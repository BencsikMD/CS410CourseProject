{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep Notebook\n",
    "\n",
    "This notebook was used to clean and format datasets. The flags in the cell below will control which actions will executed upon a \"Run All\" command of the notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data\n",
    "\n",
    "Extra tabs, linefeeds, stop words (NLTK), and punctuation will be removed. Contractions will be expanded to words. \n",
    "\n",
    "- `cleanDataSet_flag = True` -> This will run the `cleanUp()` function on the specified .csv dataset. \n",
    "- Set `cleanFilepath` to the location of the dataset to clean.\n",
    "- Set `columnsToClean` to a list of which columns to run the cleaning. Some columns should not be cleaned, such as Date or non text columns. \n",
    "\n",
    "The resulting dataset will have the same file name with `_clean` added to the end of the file name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanDataSet_flag = False\n",
    "cleanFilePath = '../Data/us_equities_news_dataset.csv'\n",
    "columnsToClean = [2,4] # range(2,26)   #[2,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Single Stock Dataset\n",
    "\n",
    "Combines news articles for individual stocks with a label of that days stock performance. If the stock's closing price is >= to the opening price, then a label of 1 is assigned to represent a gain. Otherewise, a 0 is assigned to represent a loss. \n",
    "\n",
    "- `createSingleStockDataset_flag = True` -> This will create a dataset for the selected stock. \n",
    "- Set `newsFilePath` to the location of the news dataset. Note: this file is not stored on Github due to size limits. \n",
    "- Set `tickerSymbol` to one of the stocks listed in the dictionary below. \n",
    "- Set `textChoice` to either 'title' or 'content'. This will use just the title of the news article or the content of the news article. \n",
    "\n",
    "The resulting dataset will be named XXX_TEXT_NewsDataset.csv, where XXX is the name of the stock's ticker symbol and TEXT will be Title or Content. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change these\n",
    "createSingleStockDataset_flag = False\n",
    "newsFilePath = '../Data/us_equities_news_dataset_clean.csv'\n",
    "tickerSymbol = 'AAPL'   # pick a stock ticker here\n",
    "textChoice = 'title' # 'content'    Choose 'title' of article or 'content' of the article here\n",
    "\n",
    "# Init - leave these alone\n",
    "tickerMap = {\n",
    "    'AAPL' : {'pricePath' : '../Data/HistoricalData_AAPL.csv',  },\n",
    "    'MSFT' : {'pricePath' : '../Data/HistoricalData_MSFT.csv',  },\n",
    "    'AMZN' : {'pricePath' : '../Data/HistoricalData_AMZN.csv',  },\n",
    "    'TSLA' : {'pricePath' : '../Data/HistoricalData_TSLA.csv',  },\n",
    "    'AMD'  : {'pricePath' : '../Data/HistoricalData_AMD.csv',   },\n",
    "    'NFLX' : {'pricePath' : '../Data/HistoricalData_NFLX.csv',  },\n",
    "    'SBUX' : {'pricePath' : '../Data/HistoricalData_SBUX.csv',  },\n",
    "    'GOOGL': {'pricePath' : '../Data/HistoricalData_GOOGL.csv', },\n",
    "    'BA'   : {'pricePath' : '../Data/HistoricalData_BA.csv',    },\n",
    "}\n",
    "\n",
    "priceFilePath = tickerMap['AAPL']['pricePath']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Reddit News Headlines\n",
    "\n",
    "The code was previously clean using the other functions. This just combined the headlines into one entry per data point.\n",
    "\n",
    "Setting the flag to true will re-run the combine, which is already in the Data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CombineRedditDataset_flag = False\n",
    "redditFile = '../Data/Reddit_News_DJIA_clean2_clean.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cleanDataSet_flag:\n",
    "    import os\n",
    "    parentPath = os.path.abspath('.')\n",
    "    from CleanData import CleanData\n",
    "\n",
    "    clean = CleanData(cleanFilePath, columnsToClean)\n",
    "    clean.cleanUp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Stock Data Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if createSingleStockDataset_flag:\n",
    "    import pandas as pd\n",
    "\n",
    "    def dateConvert(input):\n",
    "        input = input.split('/')\n",
    "        return input[2]+'-'+input[0]+'-'+input[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if createSingleStockDataset_flag:\n",
    "    dataFrame = pd.read_csv(newsFilePath)\n",
    "    stockDF = pd.DataFrame(dataFrame.loc[dataFrame['ticker'] == tickerSymbol])\n",
    "    stockDF.rename(columns={'release_date':'Date',textChoice:'Text'}, inplace=True)\n",
    "    priceDF = pd.read_csv(priceFilePath, converters={'Date': dateConvert})\n",
    "    priceDF['Label'] = (priceDF['Open'] <= priceDF['Close/Last']) * 1\n",
    "    combinedDF = pd.DataFrame()\n",
    "    combinedDF['Date'] = priceDF['Date']\n",
    "    combinedDF['Label'] = priceDF['Label']\n",
    "    combinedDF = combinedDF.merge(stockDF[['Text','Date']], on='Date')\n",
    "    combinedDF.to_csv('../Data/' + tickerSymbol + '_' + textChoice + '_' + 'NewsDataset.csv')\n",
    "    print('Total data points =', len(combinedDF),'\\n\\n')\n",
    "    print(combinedDF.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reddit Data Combine Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CombineRedditDataset_flag:\n",
    "    import pandas as pd\n",
    "    dataFrame = pd.read_csv(redditFile)\n",
    "    columnsDict = dict(zip(dataFrame.columns, [str]*len(dataFrame.columns)))\n",
    "    columnsDict.pop('Label')\n",
    "    dataFrame = dataFrame.astype(columnsDict)\n",
    "    combinedDF = pd.DataFrame()\n",
    "    combinedDF['Text'] = dataFrame.iloc[:,2:].apply(' '.join, axis=1)\n",
    "    combinedDF['Label'] = dataFrame['Label']\n",
    "    combinedDF.to_csv('../Data/' + 'Reddit' + '_' + 'title' + '_' + 'NewsDataset.csv')\n",
    "    print('Total data points =', len(combinedDF),'\\n\\n')\n",
    "    print(combinedDF.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51d32a615755070830a1e212317cdba8790c54f51db92b1c7f00b70a02f13d97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
